{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6jstdpA0dbV"
      },
      "source": [
        "# **ConvNet From Scratch with augmentations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4LGipAK0poK"
      },
      "source": [
        "This will contain:\n",
        "1. image augmentation for increasing the volume of input  \n",
        "2. visualization of intermediate features and images\n",
        "3. Fine-tuning the known architecture for the sake of learning\n",
        "\n",
        "All will be coded in PyTorch\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlUhi_tOwvyK"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTHNcNqD2eVU",
        "outputId": "f7a11096-b5ca-49ed-b5c0-f50c8f1d5713"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "#Loading the datasets\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(\n",
        "    root = 'data',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transform\n",
        ")\n",
        "\n",
        "test_dataset = datasets.CIFAR10(\n",
        "    root = 'data',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = transform\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG8gTt0B-kot"
      },
      "source": [
        "\"Since we are using the concept of data augmentation, we will be using less samples of data. Currently, we have 5000 samples for cat and dogs each. But, we will use the dataset with 1000 training images, 500 validation imgages and 1000 test images\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcY7v53c7fEj"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Subset\n",
        "def create_balanced_subset(dataset, class_indices, start_index, end_index):\n",
        "\n",
        "  targets = np.array(dataset.targets)\n",
        "  selected_indices = []\n",
        "\n",
        "  for cls in class_indices:\n",
        "    indices = np.where(targets == cls)[0]\n",
        "    selected_indices.extend(indices[start_index: end_index])\n",
        "\n",
        "  dataset = Subset(dataset, selected_indices)\n",
        "  return dataset\n",
        "\n",
        "train_data = create_balanced_subset(train_dataset, [3,5], 0, 1000)\n",
        "validation_data = create_balanced_subset(train_dataset, [3,5], 1000, 1500)\n",
        "test_data = create_balanced_subset(test_dataset, [3,5], 0, 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjdTmfaW9jo1",
        "outputId": "216f991d-a77e-4999-d8ee-3b5156abc689"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def check_subset_balance(subset, name=\"Subset\"):\n",
        "    # This pulls labels from the original dataset using the subset's internal indices\n",
        "    labels = [subset.dataset.targets[i] for i in subset.indices]\n",
        "\n",
        "    unique, counts = np.unique(labels, return_counts=True)\n",
        "    print(f\"--- {name} ---\")\n",
        "    print(f\"Total samples: {len(subset)}\")\n",
        "    for cls, count in zip(unique, counts):\n",
        "        print(f\"Class {cls}: {count} samples\")\n",
        "\n",
        "check_subset_balance(train_data, \"Training Set\")\n",
        "check_subset_balance(validation_data, \"Validation Set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wY_11HZ-QhxO"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "#Changing the class 3 -> 0 and 5 -> 1\n",
        "class DatasetWrapper:\n",
        "  def __init__(self, subset, mapping = {3 : 0, 5: 1}, transform = None):\n",
        "    self.subset = subset\n",
        "    self.mapping = mapping\n",
        "    self.transform = transform\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image, target = self.subset[index]\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "    return image, self.mapping[target]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.subset)\n",
        "\n",
        "train_ready = DatasetWrapper(train_data)\n",
        "validation_ready = DatasetWrapper(validation_data)\n",
        "test_ready = DatasetWrapper(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUxtFD-fU_HM"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "#Creating dataloader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_ready, batch_size, shuffle = True)\n",
        "val_loader = DataLoader(validation_ready, batch_size, shuffle = True)\n",
        "test_loader = DataLoader(test_ready, batch_size, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "gJLD_kZLWetb",
        "outputId": "1a552508-be50-4578-f6e4-360e4f5cc435"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "images = images[:32].numpy()\n",
        "images = np.transpose(images, (0, 2, 3, 1)) #Channel to the last\n",
        "label_mappings  = {\n",
        "    0: \"Cat\",\n",
        "    1: \"Dog\"\n",
        "}\n",
        "plt.figure(figsize = (20, 10))\n",
        "for i in range(len(images)):\n",
        "  plt.subplot(4, 8, i + 1)\n",
        "  plt.imshow(images[i])\n",
        "  plt.xlabel(f\"Label: {label_mappings[labels[i].item()]}\")\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "plt.show()\n",
        "#Visualizing the first batch of the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqJBIEeQBDFm",
        "outputId": "1c55864a-e2c9-4fad-86eb-a29bb4190f9b"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qD5jXS5B1Rl"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from torch.nn.modules import activation\n",
        "from torchsummary import summary\n",
        "#Defining the model\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.ConV_stack = nn.Sequential(\n",
        "\n",
        "        nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2),\n",
        "\n",
        "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2),\n",
        "\n",
        "        nn.Conv2d(in_channels = 64, out_channels=128, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2),\n",
        "\n",
        "        nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2),\n",
        "\n",
        "        nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        nn.AdaptiveAvgPool2d(1),\n",
        "        nn.Flatten(),\n",
        "\n",
        "        nn.Linear(512, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, X):\n",
        "    Y = self.ConV_stack(X)\n",
        "    return Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AC9PpyvSMs6d",
        "outputId": "5807cbf4-6c5d-431c-cfd3-a274c6929c0f"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "device = torch.accelerator.current_accelerator() if torch.accelerator.is_available() else \"cpu\"\n",
        "model = NeuralNetwork().to(device)\n",
        "summary(model, (3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHGtaWs_RQHo"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "#Defining the optimizer and the loss function for the model\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr = 1e-3)\n",
        "criterion = nn.BCELoss()\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wM2iWAc4TIpH"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "#Defining the training function\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(dataloader, model, optimizer, loss_fn):\n",
        "  num_batches = len(dataloader)\n",
        "\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  pbar = tqdm(dataloader, desc = \"Training\", leave = True)\n",
        "\n",
        "  for (X, y) in pbar:\n",
        "    X, y = X.to(device), y.to(device).float().unsqueeze(1)\n",
        "\n",
        "    y_pred = model.forward(X)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    pred = (y_pred > 0.5).float()\n",
        "    correct += (pred == y).sum().item()\n",
        "    total += X.size(0)\n",
        "\n",
        "    pbar.set_postfix(\n",
        "          loss = f\"{(running_loss/(total / X.size(0)))}\",\n",
        "          accuracy = f\"{correct/total}\"\n",
        "    )\n",
        "\n",
        "  train_loss = running_loss / num_batches\n",
        "  accuracy = correct / total\n",
        "\n",
        "  return train_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Y3VwkP6VUZw"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "#Define func for Validation and Test\n",
        "from tqdm import tqdm\n",
        "\n",
        "def infer(dataloader, model, loss_fn):\n",
        "  num_batches = len(dataloader)\n",
        "\n",
        "  inference_loss = 0.0\n",
        "  inference_accuracy = 0.0\n",
        "  total = 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "   pbar = tqdm(dataloader, desc = \"Validation\", leave = True)\n",
        "\n",
        "   for X, y in pbar:\n",
        "      X, y = X.to(device), y.to(device).float().unsqueeze(1)\n",
        "\n",
        "      y_pred = model.forward(X)\n",
        "      loss = loss_fn(y_pred, y)\n",
        "\n",
        "      inference_loss += loss.item()\n",
        "      predicted = (y_pred > 0.5).float()\n",
        "      correct = (predicted == y).sum().item()\n",
        "\n",
        "      inference_accuracy += correct\n",
        "      total += X.size(0)\n",
        "\n",
        "      pbar.set_postfix(\n",
        "          loss = f\"{(inference_loss/(total / X.size(0)))}\",\n",
        "          accuracy = f\"{inference_accuracy/total}\"\n",
        "      )\n",
        "\n",
        "  inference_loss /= num_batches\n",
        "  inference_accuracy /= total\n",
        "\n",
        "  return inference_loss, inference_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T4ouPYw4Yila",
        "outputId": "b5e8976a-2ab7-4ca7-ef36-15ee94c60319"
      },
      "outputs": [],
      "source": [
        "#Let's train, validate and test with model checkpoint\n",
        "from tqdm import tqdm\n",
        "\n",
        "epochs = 50\n",
        "best_val_loss = float('inf')\n",
        "save_path = \"best_mode.pth\"\n",
        "\n",
        "history = {\n",
        "    'train_loss': [],\n",
        "    'train_acc' : [],\n",
        "    'val_loss' : [],\n",
        "    'val_acc': [],\n",
        "}\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    #Training\n",
        "    train_loss, train_acc = train(train_loader, model, optimizer, criterion)\n",
        "\n",
        "    #Validation\n",
        "    val_loss, val_acc = infer(val_loader, model, criterion)\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['val_acc'].append(val_acc)\n",
        "\n",
        "    #Model Checkpoint\n",
        "    if val_loss < best_val_loss:\n",
        "      best_val_loss = val_loss\n",
        "      torch.save(model.state_dict(), save_path)\n",
        "      print(f\"Model saved to {save_path} \")\n",
        "\n",
        "print(\"Training Complete\")\n",
        "\n",
        "#Testing\n",
        "test_loss, test_acc = infer(test_loader, model, criterion)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {(test_acc * 100):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfNm6Fslz6LQ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "accuracy = history['train_acc']\n",
        "val_accuracy = history['val_acc']\n",
        "loss = history['train_loss']\n",
        "val_loss = history['val_loss']\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize = (20, 10))\n",
        "\n",
        "axes[0].plot(epochs, accuracy, 'r--', label = \"Training Accuracy\")\n",
        "axes[0].plot(epochs, val_accuracy, 'b', label = \"Validation Accuracy\")\n",
        "axes[0].set_title(\"Training and Validation Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "axes[1].plot(epochs, loss, 'r--', label = \"Training Loss\")\n",
        "axes[1].plot(epochs, val_loss, 'b', label = \"Validation Loss\")\n",
        "axes[1].set_title(\"Training and Validation Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P71wADf521Pu"
      },
      "outputs": [],
      "source": [
        "#Visualize sample predictions\n",
        "\n",
        "best_model = NeuralNetwork()\n",
        "best_model.load_state_dict(torch.load('best_mode.pth'))\n",
        "\n",
        "best_model.eval()\n",
        "images, label = next(iter(test_loader))\n",
        "\n",
        "image = images[0].to(device)\n",
        "with torch.no_grad():\n",
        "  pred = best_model(images)\n",
        "  predicted = (pred > 0.5).float().cpu().squeeze()\n",
        "\n",
        "print(f\"Predicted {predicted}\")\n",
        "\n",
        "label_map = {\n",
        "    0: \"Cat\",\n",
        "    1: \"Dog\"\n",
        "}\n",
        "images = images.cpu().numpy()\n",
        "images = np.transpose(images, (0, 2, 3, 1))\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "for i in range(16):\n",
        "  plt.subplot(4,4, i + 1)\n",
        "  image = images[i]\n",
        "  plt.imshow(image)\n",
        "  plt.title(f\"Correct Label: {label_map[label[i].item()]}\")\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.xlabel(f\"Predicted Lable: {label_map[predicted[i].item()]}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFjSzCNaOH8C"
      },
      "source": [
        "Since this just gave the accuracy of about 70 %, we are going to use the data augmentation technique\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MBwI3YPOPdM"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((180, 180)),\n",
        "    transforms.ToPILImage(), #Since the input is Tensor as we transformed in the top\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast = 0.2),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose(\n",
        "    [transforms.Resize((180, 180))]\n",
        ")\n",
        "\n",
        "augmented_train_ready = DatasetWrapper(train_data, transform=train_transform)\n",
        "val_ready = DatasetWrapper(validation_data, transform=test_transform)\n",
        "test_ready = DatasetWrapper(test_data, transform= test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFrPSulVP1N_"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "#Visualizing the Data Augmentation\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(\n",
        "    augmented_train_ready,\n",
        "    batch_size, \n",
        "    shuffle = True, \n",
        "    num_workers=0,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ready, \n",
        "    batch_size, \n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_ready, \n",
        "    batch_size, \n",
        "    shuffle = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "images, labels = next(iter(train_loader))\n",
        "images = np.transpose(images, (0, 2, 3, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "\n",
        "plt.figure(figsize =(15, 10))\n",
        "for i in range(16):\n",
        "    plt.subplot(4,4, i+1)\n",
        "    plt.imshow(images[i])\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "#Visualization of the Data Augmentation\n",
        "img = images[0]\n",
        "\n",
        "plt.figure(figsize = (15, 10))\n",
        "\n",
        "for i in range(8):\n",
        "    plt.subplot(2, 4, i+1)\n",
        "    aug_image, label = augmented_train_ready[0]\n",
        "\n",
        "    aug_image = aug_image.permute(1, 2, 0).numpy()\n",
        "\n",
        "    plt.subplot(2, 4, i +1)\n",
        "    plt.imshow(aug_image)\n",
        "    plt.title(f\"Aug {i+1}\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from torch.nn.modules import activation\n",
        "from torchsummary import summary\n",
        "\n",
        "# Defining the model\n",
        "\n",
        "\n",
        "class AugNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.ConV_stack = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = self.ConV_stack(X)\n",
        "        return Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "model = AugNN().to(device)\n",
        "summary(model, (3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Defining the optimizer and the loss function for the model\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-3)\n",
        "criterion = nn.BCELoss()\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"min\", patience=5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training, Validating and Testing\n",
        "from tqdm import tqdm\n",
        "\n",
        "epochs = 50\n",
        "best_val_loss = float(\"inf\")\n",
        "save_path = \"best_mode.pth\"\n",
        "\n",
        "history = {\n",
        "    \"train_loss\": [],\n",
        "    \"train_acc\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"val_acc\": [],\n",
        "}\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    # Training\n",
        "    train_loss, train_acc = train(train_loader, model, optimizer, criterion)\n",
        "\n",
        "    # Validation\n",
        "    val_loss, val_acc = infer(val_loader, model, criterion)\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "    history[\"val_loss\"].append(val_loss)\n",
        "    history[\"train_acc\"].append(train_acc)\n",
        "    history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "    # Model Checkpoint\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"Model saved to {save_path} \")\n",
        "\n",
        "print(\"Training Complete\")\n",
        "\n",
        "# Testing\n",
        "test_loss, test_acc = infer(test_loader, model, criterion)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {(test_acc * 100):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "accuracy = history[\"train_acc\"]\n",
        "val_accuracy = history[\"val_acc\"]\n",
        "loss = history[\"train_loss\"]\n",
        "val_loss = history[\"val_loss\"]\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "axes[0].plot(epochs, accuracy, \"r--\", label=\"Training Accuracy\")\n",
        "axes[0].plot(epochs, val_accuracy, \"b\", label=\"Validation Accuracy\")\n",
        "axes[0].set_title(\"Training and Validation Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "axes[1].plot(epochs, loss, \"r--\", label=\"Training Loss\")\n",
        "axes[1].plot(epochs, val_loss, \"b\", label=\"Validation Loss\")\n",
        "axes[1].set_title(\"Training and Validation Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Feature Extraction without Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import timm\n",
        "import torch\n",
        "from torchsummary import summary\n",
        "\n",
        "conv_base = timm.create_model('xception', pretrained=True, num_classes = 0, global_pool = '')\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "conv_base = conv_base.to(device)\n",
        "summary(conv_base, (3, 180,180))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "test_image = torch.randn(1, 3, 180,180)\n",
        "test_image = test_image.to(device)\n",
        "output = conv_base(test_image)\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((180, 180)),\n",
        "])\n",
        "\n",
        "train_ready = DatasetWrapper(train_data, transform = preprocess)\n",
        "train_loader = DataLoader(train_ready, batch_size, shuffle=True)\n",
        "\n",
        "images, _ = next(iter(train_loader))\n",
        "images[0].min(), images[0].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Extracting the feature\n",
        "conv_base.eval()\n",
        "def get_features_and_labels(dataloader):\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images = images.to(device)\n",
        "            features = conv_base(images)\n",
        "            all_features.append(features.cpu().numpy())\n",
        "            all_labels.append(labels)\n",
        "        \n",
        "    return np.concatenate(all_features), np.concatenate(all_labels)\n",
        "\n",
        "train_features, train_labels = get_features_and_labels(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "val_features, val_labels = get_features_and_labels(val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "test_features, test_labels = get_features_and_labels(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "#Defining the classifier model\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "\n",
        "class LinearClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(2048, 256),\n",
        "            nn.ReLU(), \n",
        "            nn.Dropout(0.25),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self, X):\n",
        "        X = self.gap(X)\n",
        "        X = self.flatten(X)\n",
        "        return self.classifier(X)\n",
        "\n",
        "model = LinearClassifier().to(device)\n",
        "summary(model, ((2048, 6, 6)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.0)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import torch \n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "train_features_t = torch.from_numpy(train_features).float()\n",
        "train_labels_t = torch.from_numpy(train_labels).float()\n",
        "\n",
        "val_features_t = torch.from_numpy(val_features).float()\n",
        "val_labels_t = torch.from_numpy(val_labels).float()\n",
        "\n",
        "test_features_t = torch.from_numpy(test_features).float()\n",
        "test_labels_t = torch.from_numpy(test_labels).float()\n",
        "\n",
        "train_ds = TensorDataset(train_features_t, train_labels_t)\n",
        "val_ds = TensorDataset(val_features_t, val_labels_t)\n",
        "test_ds = TensorDataset(test_features_t, test_labels_t)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle = True)\n",
        "val_loader = DataLoader(val_ds, batch_size = 32)\n",
        "test_loader = DataLoader(test_ds, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2000])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_labels_t.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 63/63 [00:00<00:00, 153.50it/s, accuracy=0.539, loss=0.348296257019043]              \n",
            "Validation: 100%|██████████| 32/32 [00:00<00:00, 258.03it/s, accuracy=0.526, loss=0.17703984594345093]            \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to best_mode.pth \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 63/63 [00:00<00:00, 205.98it/s, accuracy=0.5385, loss=0.3485322675704956]            \n",
            "Validation: 100%|██████████| 32/32 [00:00<00:00, 250.49it/s, accuracy=0.526, loss=0.17703984594345093]            \n",
            "Training: 100%|██████████| 63/63 [00:00<00:00, 210.29it/s, accuracy=0.5455, loss=0.3482172832489014]            \n",
            "Validation: 100%|██████████| 32/32 [00:00<00:00, 251.52it/s, accuracy=0.526, loss=0.17703984594345093]            \n",
            "Training: 100%|██████████| 63/63 [00:00<00:00, 198.94it/s, accuracy=0.5255, loss=0.348206063747406]             \n",
            "Validation: 100%|██████████| 32/32 [00:00<00:00, 221.80it/s, accuracy=0.526, loss=0.17703984594345093]            \n",
            "Training: 100%|██████████| 63/63 [00:00<00:00, 212.56it/s, accuracy=0.5245, loss=0.3487097144126892]            \n",
            "Validation: 100%|██████████| 32/32 [00:00<00:00, 196.35it/s, accuracy=0.526, loss=0.17703984594345093]            \n",
            "Training: 100%|██████████| 63/63 [00:00<00:00, 199.28it/s, accuracy=0.5495, loss=0.3482811374664307]            \n",
            "Validation: 100%|██████████| 32/32 [00:00<00:00, 243.26it/s, accuracy=0.526, loss=0.17703984594345093]            \n",
            "Training: 100%|██████████| 63/63 [00:00<00:00, 214.04it/s, accuracy=0.53, loss=0.3481970009803772]              \n",
            "Validation: 100%|██████████| 32/32 [00:00<00:00, 248.19it/s, accuracy=0.526, loss=0.17703984594345093]            \n",
            "Training: 100%|██████████| 63/63 [00:00<00:00, 212.83it/s, accuracy=0.5355, loss=0.34844264030456545]           \n",
            "Validation: 100%|██████████| 32/32 [00:00<00:00, 240.35it/s, accuracy=0.526, loss=0.17703984594345093]            \n",
            "Training: 100%|██████████| 63/63 [00:00<00:00, 206.17it/s, accuracy=0.552, loss=0.3479335384368896]             \n",
            "Validation: 100%|██████████| 32/32 [00:00<00:00, 247.36it/s, accuracy=0.526, loss=0.17703984594345093]            \n",
            "Training: 100%|██████████| 63/63 [00:00<00:00, 214.74it/s, accuracy=0.535, loss=0.34850870656967164]            \n",
            "Validation: 100%|██████████| 32/32 [00:00<00:00, 242.28it/s, accuracy=0.526, loss=0.17703984594345093]            \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Complete\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation:   0%|          | 0/63 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (32x3 and 2048x256)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining Complete\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Testing\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m test_loss, test_acc = \u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(test_acc\u001b[38;5;250m \u001b[39m*\u001b[38;5;250m \u001b[39m\u001b[32m100\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36minfer\u001b[39m\u001b[34m(dataloader, model, loss_fn)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[32m     18\u001b[39m    X, y = X.to(device), y.to(device).float().unsqueeze(\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m    y_pred = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m    loss = loss_fn(y_pred, y)\n\u001b[32m     23\u001b[39m    inference_loss += loss.item()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mLinearClassifier.forward\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     20\u001b[39m X = \u001b[38;5;28mself\u001b[39m.gap(X)\n\u001b[32m     21\u001b[39m X = \u001b[38;5;28mself\u001b[39m.flatten(X)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\Rijan_Shrestha\\AI\\AI Works\\Paper-Reproduction\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\Rijan_Shrestha\\AI\\AI Works\\Paper-Reproduction\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\Rijan_Shrestha\\AI\\AI Works\\Paper-Reproduction\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\Rijan_Shrestha\\AI\\AI Works\\Paper-Reproduction\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\Rijan_Shrestha\\AI\\AI Works\\Paper-Reproduction\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\Rijan_Shrestha\\AI\\AI Works\\Paper-Reproduction\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (32x3 and 2048x256)"
          ]
        }
      ],
      "source": [
        "# Training, Validating and Testing\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "\n",
        "save_path = \"best_mode.pth\"\n",
        "\n",
        "\n",
        "history = {\n",
        "\n",
        "    \"train_loss\": [],\n",
        "\n",
        "    \"train_acc\": [],\n",
        "\n",
        "    \"val_loss\": [],\n",
        "\n",
        "    \"val_acc\": [],\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "\n",
        "    # Training\n",
        "\n",
        "    train_loss, train_acc = train(train_loader, model, optimizer, criterion)\n",
        "\n",
        "\n",
        "    # Validation\n",
        "\n",
        "    val_loss, val_acc = infer(val_loader, model, criterion)\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "\n",
        "    history[\"val_loss\"].append(val_loss)\n",
        "\n",
        "    history[\"train_acc\"].append(train_acc)\n",
        "\n",
        "    history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "\n",
        "    # Model Checkpoint\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "\n",
        "        print(f\"Model saved to {save_path} \")\n",
        "\n",
        "\n",
        "print(\"Training Complete\")\n",
        "\n",
        "\n",
        "# Testing\n",
        "\n",
        "test_loss, test_acc = infer(test_loader, model, criterion)\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "print(f\"Test Accuracy: {(test_acc * 100):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "from torchsummary import summary\n",
        "\n",
        "conv_base = timm.create_model('xception', pretrained=True, num_classes = 0, global_pool = '')\n",
        "\n",
        "for param in conv_base.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "class IntegratedModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        self.base = conv_base\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(2048, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self, X):\n",
        "        X = self.base(X)\n",
        "        X = self.gap(X)\n",
        "        X = self.flatten(X)\n",
        "        return self.classifier(X)\n",
        "\n",
        "model = IntegratedModel().to(device)\n",
        "summary(model, (3, 180,180))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
